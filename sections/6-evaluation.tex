\section{Evaluation}
We evaluated \projname through a controlled user study with twelve participants recruited using university and professional networks. Specifically, we compare an instance of \projname to a language-based method. The choice of a language-based method for comparison is based on its widespread deployment to instruct robots~\cite{team2024octo, zha2023distilling}.

\emph{Conditions.} To enable a fair comparison of each modality, we omitted all the language features of \projname, including the ability to generate new images using language instructions or modify them using captions. For the language condition, we re-purposed \projname, replacing all image-based interactions with text. Instead of populating images in the timeline, the user populates the timeline with steps that consist of text. For the image-based method in \projname, we omit all language-based features (e.g., modifying images with captions) as well as autocomplete at the manipulation and step levels. In both the conditions, participants provided instructions pertaining to one object at a time, reflecting the current capabilities of robots, which typically handle single-object manipulation. Further, most language-conditioned robot policies, including foundation models, follow a similar approach, executing single language instructions at a time. While large language models can interpret more abstract instructions and decompose them, they are prone to errors and often require corrections~\cite{zha2023distilling}.

\emph{Study design.} The study utilizes a within-subjects design with two conditions--image and text--that are counterbalanced to minimize ordering effects (see Figure X for a full diagram). Within each condition, participants complete four tasks where they instruct a robot to complete kitchen manipulation tasks. The tasks include \textit{Organizing Pantry}, \textit{Sorting Fruits}, \textit{Preparing Stirfry}, and \textit{Washing Dishes}. Within each condition, the four tasks were randomly assigned. After both condition blocks, participants complete a freeform task to experiment with the features that were excluded from \projname. Details of the individual tasks can be found in the appendices (\mk{link}) and the website.

\emph{Measures.} In the study, we collected data about participants' performance when using both methods. Quantitative measures include task completion time and number of errors, which were determined by comparison to an \textit{oracle} representation of the task established a priori by two researchers. We also measured subjective perceptions of the prototypes, including participants' confidence in correctly communicating their intent to the robot, workload (NASA TLX~\cite{hart2006nasa}), and usability (SUS~\cite{bangor2008empirical}).

\emph{Procedure.} Participants first provided consent and completed a pre-study questionnaire assessing their familiarity with robots and instructing them. After watching a video tutorial introducing \projname and the text-based method and brief experimentation with both, participants began one of the two study condition blocks. Between tasks, participants rated how confident they were that the robot could understand their instructions unambiguously. At the end of each condition block, two questionnaires (NASA TLX and SUS) were administered to assess workload and usability, respectively. At the end of the study, participants rated their preference for the text-based method compared to \projname. Lastly, we conducted a brief interview probing participants about various aspects of both methods.

\emph{Hypotheses.} We formulated three hypotheses: Participants will complete tasks faster using the \projname compared to the text-based method (\emph{H1}); Participants will make fewer errors using the \projname compared to the text-based method (\emph{H2}); Participants will feel more confident that a robot unambiguously understands their instructions when using \projname compared to the text-based method (\emph{H3}).

\emph{Findings.} 