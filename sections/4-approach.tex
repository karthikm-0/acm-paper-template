\section{\projname Interactions}
\projname assumes a set-up phase where the robot builds an internal representation of the user's environment. This representation consists of objects that can be stateless or fixtures that are stateful (i.e., take on states). For instance, some items, like bowls, are \textit{objects} because they do not have states (but can vary in location or contents). Other items, like furniture (e.g., drawers) or appliances (e.g., stovetops) are \textit{fixtures} because they can be in one or more states (e.g., open or closed in the case of drawers). Imagine that a user wants to wash dishes after a meal. We walk through the interactions that the user might have with \projname to instruct the robot to complete this task.

%In our specific implementation, stateless objects are called \emph{items}, such as food (e.g., fruits) and utensils (e.g., bowls). \mk{Figure}. In contrast, stateful objects are called \emph{fixtures} which includes furniture (e.g,, cabinets and drawers) as well as appliances (e.g., stovetops or sinks). For instance, a drawer may be open or closed, and a stovetop may have any of its burners on or off. Once this representation is created, \projname keeps track of the current state as well as possible future states.

% In our implementation, we assume access to the initial state of fixtures (but not objects) as well as knowledge about the states they can possible take (e.g,, that a drawer can be open or closed). 

% Define step here as it pertains to user (not robot)
\noindent \emph{Timeline.} The user interacts with \projname through a timeline that represents the current state of the environment as well as the desired changes. When the user starts \projname, a step representing the current world state populates the timeline. All future steps represent changes from this initial step which the robot treats as instructions. In the timeline, images for each step are displayed from left to right and visualized as smaller thumbnails. Each step includes buttons that allow the user to copy or delete the step. Copying a step creates a new step with the same image, which the user can then modify. Deleting a step removes it from the timeline.

\noindent \emph{Editor.} To support the creation of new instructions, the user can click any step in the timeline. This highlights the step in the timneline and populates it inside an image editor which appears above the timeline. The editor supports the manipulation of objects and fixtures in the environment.

% \emph{Defining steps.} In \projname, a \textit{step} represents a desired change requested by the user to update the environment's state. Suppose the user wants the robot to put a dirty dish on the counter into the sink for rinsing. Steps here are defined as changes from the user's perspective. Thus, a possible next step could be for the dirty dish to be on the counter. Note that for a robot, executing this single step requires several actions: the robot needs to first pick up the dirty dish, and then place it in the sink.

\noindent \emph{Interactable objects and fixtures.} Once the editor appears, the user can perform simple drag and drop manipulations on recognized objects. When the user manipulates an object, it automatically populates a step in the timeline to the right of the selected step, and populates the editor with the new image. Continuously manipulating the same object does not create additional steps, which allows the user to refine the object's position without creating unnecessary steps.

In \projname, the user can manipulate the state of recognized fixtures by clicking on them. This triggers the creation of a new step where the image represents the environment with the fixture's state having updated.

\noindent \emph{Visualizing step changes.} To help the user understand the changes between steps, \projname implements two visualization techniques. First, to quickly delineate changes between one step and the next, \projname highlights the differences between the two images. When the change involves an object moving, it is highlighted while other objects and the background containing fixtures are lower in opacity. Second, when the user hovers over a step in the timeline while having a step selected, a looping animation shows the changes between them. For object manipulations, the animation shows the object moving from one position to another. For fixture manipulations, the animation shows the fixture transitioning between states.

\noindent \emph{Language-based editing.} When a step is selected in the timeline and appears in the editor, the user can input an instruction using natural language to request new steps. The instruction can be specific and pertain to the next step (e.g., \textit{``open the cabinet''}) in which case a single step would be generated. In contrast, a more abstract instruction (e.g., wash the fruits) could result in several steps (e.g., washing the fruits could involve washing each fruit under the sink).

\noindent \emph{Captioning steps.} To provide additional context to the user, \projname automatically generates captions for each step in the timeline. These captions describe the changes between the current step and the previous step. For instance, if the user moves a small plate among other plates on the counter into the sink, the caption might read \textit{``move the small plate from the left of the counter into the sink''}. In some cases, the user may not be satisfied with their manipulation and may choose to modify the caption, which modifies the image in the step to reflect the new caption. In other cases, the user might be satisfied with the visual outcome of their manipulation, but wants to include context that is not captured by the caption but could be useful for future steps (e.g., that they eat cereal every morning so it should be easy to reach). To achieve this, the user unlink the caption from the image and then modify it.

\noindent \emph{Autocompleting steps.} When the user selects an object, \projname proposes locations for the object based on what is available in the environment. For instance, in an environment containing a sink and several bowls, selecting an orange on the counter proposes manipulations towards the bowls and the sink. Each of these is represented as a colored line originating from the object. Clicking a line manipulates the object to the destination and populates a step in the timeline.

As the user adds new steps to the timeline by manipulating objects and fixtures, \projname uses the context underlying existing steps in the timeline to propose plausible next steps, which are visualized outside the timeline. Selecting a plausible step automatically populates it to the timeline and rejects the others.

%%%% Types of autocomplete
% Proposing next steps based on existing steps - useful
% Using object selection or current step to propose text (when using input bar) - less useful
% Taking an interaction done by the user (e.g., dragging plate to sink) and proposing an action (drag x to y) automatically (ripped from Damien)
% Proposing the step when an item is selected inside the current step (e.g., plate selected -> can go to cabinet, sink, counter??)


%% What interactions are possible; for now drag/drop + click to change states


% Reg drag and drop 

% Articulated objects



% Autocomplete features


%\subsection{GIFs}
